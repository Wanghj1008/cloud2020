1.NOSQL:not only sql(不仅仅是sql)四大分类
    1.键值对存储：Redis（C编写）、memcache    【用途：缓存、数据库】
        优点：查找速度快                      缺点：数据没有结构,通常只被当作字符串
    2.文档型数据库： MongoDB(C++编写)
        优点：数据结构要求不严格                缺点：查询速度低
    3.列存储数据库： Hbase                 【用途：分布式文件系统】
        优点：查找速度快,可拓展性强             缺点：功能相对局限性。因为是以列存储的
    4.图形关系数据库： Neo4j                【用途：社交网络,朋友圈,广告推荐】
        优点：利用图结构算法,查找最短路径        缺点：很多时候需要所有数据才能得出结论,不好做分布式集群
2.关系型数据库和非关系型数据库区别？
    1.关系型数据库(RDBMS)
        优点:1.提供规范的SQL语句进行数据处理   2.事务控制,方便回滚
    2.非关系型数据库(NOSQL)
        优点:1.大数据量下读写性能高   2.数据之间无关联,不需要实现设计库表
3.Redis优缺点:全称远程字典服务(C编写)
    优点：读写性能高,支持多种数据类型,具有高可用性(持久化,主从复制,哨兵,集群)
        1、持久化：内存数据保存到硬盘,防止进程重启数据丢失
        2、主从复制：读写分离,写操作同步给从机,但是主机宕机需要手动选一个备机成为主机(人工无法做到实时切换,会造成写操作长时间不可用)
        3、哨兵：自动检查节点状态,实现主机宕机短时间内自动选取备机成为主机
        4、集群：解决写操作负载均衡并且提高存储空间 实现高可用
    缺点：数据库容量受到物理内存的限制,主机宕机可能造成数据丢失,redis在线扩容非常复杂,所以上线就进行了集群配置,造成前期资源浪费
    用处：数据库,缓存系统,消息队列,分布式锁,地理位置,访客统计,排行榜
4.Redis底层数据结构
    1.简单动态字符串SDS(String底层数据结构)
        1.C字符串长度需要遍历计算,而sds进行了保存
        2.C未使用空间无保存,可能造成内存溢出,sds中保存了未使用空间
        3.C只能保存文本数据,sds可以保存文本和二进制数据
    2.压缩列表：
        当元素长度都小于64字节时采用压缩列表来节约内存
    3.跳跃表：
        维护多个指针,从而提高范围查询效率
    4.字典：
        用来保存键值对类型,提高查询效率
    5.链表(C中无链表)
        前后节点组成双向链表,表头和表尾为null
5.Sorted Set 为什么同时使用字典和跳跃表？Sorted Set 为什么使用跳跃表，而不是红黑树？
    1.字典提高查询效率,跳跃表提高范围查询效率
    2.因为红黑树实现相对比复杂,性能也差不多,所以采取简单的方式
6.Hash 对象底层结构(压缩列表和字典),rehash大数据量下会有问题吗？
    1.渐进式 rehash：采用分而治之的方式将大计算量分摊到每个增删改查操作上,如果内存接近最大内存并且有设置策略的情况下会触发淘汰.
----------------------------------------------------------------------------
常用Redis命令：  16数据库(0~15):默认是0
    1.select 3:切换数据库    2.move name 1:将name移动到1数据库    3.DBSize:查看当前库的大小    4.expire name 10:10s过期时间
    5.flushAll:清空全表      6.flushdb:清空当前库                7.type:查看key的类型        8.Exists key：判断key是否存在
1.String类型
    1.incr key:i++    2.decr key：i--    3.incrBy key 5:i+5    4.decrBy key 5:i-5    5.StrLen key:获取字符串长度
    6.mset:批量插入     7.mget:批量获取     8.setex:set+expire    9.append:拼接或set    10.getset：先get后set
    11.setnx：不存在插入    12.msetnx：不存在批量插入(一个存在全部失败)    13.del：删除
2.List类型： 栈、消息队列、双端队列、阻塞队列
    1.lpush:左插     2.rpush:右插     3.lpop:左取     4.rpop:右取    5.lrange key 0 -1：左查全部元素
    6.rpopLpush:一个list取出放入另一个list
3.Set类型：共同关注,共同爱好,推荐好友,（六度分割理论）
    1.sdiff:差集    2.sinter：交集     3.sunion：并集    4.sadd：插入    5.smembers：查询所有   6.spop：随机移除一个key
4.Hash类型：键值对形式,适合存储用户信息,session数据
    1.hset：插入    2.hmset：批量插入    3.hget：获取     4.hmget：批量获取    5.hdel：删除    6.hgetall:获取所有key
5.Zset类型： 排行榜
    1.zadd：插入  2.zrangeByscore key -inf +inf (withscore)：查询指定范围元素(携带成绩)   3.zrange：查询所有元素   4.zrem：删除元素
6.geospatial(地理位置)
    1.geodist：两地距离   2.georadius：附近的人
7.hyperloglog基数统计：占用内存小,存在80%误差(可用作网站真实人数访问统计)
8.bitmap位图： 位存储,节约内存,打卡信息统计等
9.Stream流：
-----------------------------------------------------------------------------------------------
Redis事务操作：单条语句具有原子性,多条没有原子性
  错误类型：
     1.编译错误    全部都不执行(语法错误。指令出错)
     2.运行错误    错误的不执行,正确的都可以执行
     3.不支持回滚
  开启事务 multi    语句。。。。。    exec执行事务。   discard 取消事务
  其他实现方式：redis脚本(LUA)也可以实现事务,实际使用推荐这种方式,可以保证脚本内所有命令的一致性
Watch 监控事务：
  watch命令可以决定事务会回滚还是提交。在事务multi开启之前开启watch监控一些键值对。exec提交的时候检查。键值对没有被其他线程修改
  则提交事务,如果值被修改,则回滚事务。 乐观锁的思想,类似于判断版本。和多线程中CAS的原子引用的乐观锁类似。
  开启：  watch key    取消1.事务exec执行完毕。无论成功失败监控都取消 2.客户端推出 3.手动unwatch 取消
Redis 的 Java 客户端有哪些？官方推荐哪个？
    1.Jedis(提供丰富的redis指令)    2.Redisson(基于分布式场景的解决方案)   3.lettuce
整合Spring boot： 2.X版本后采用 lettuce
    Jedis：采用直连,多个线程操作是不安全的,避免不安全,加入jedis pool连接池，更像BIO模式
    lettuce:底层使用netty,实例可以在多个线程间共享,不存在线程不安全,可以减少线程数，更像NIO模式
-----------------------------------------------------------------------------------------------
Redis redis.conf配置文件
INCLUDES：可以导入其他配置文件
    例如 include /path/to/other.conf 可以把其他的配置文件配置进来
网络配置：NETWORK
    绑定IP：默认 bind 127.0.0.1   如果需要外网访问,需要设置0.0.0.0
    保护模式：默认 protected-mode yes：如果需要外网访问,设置no,不然外网访问报错
    端口号：port 6379
通用配置：GENERAL
    守护线程：默认daemonize no  启动守护线程后台运行
    日志级别： logLevel 默认notice
        # debug (a lot of information, useful for development/testing)大量的信息，一般用于开发/测试阶段
        # verbose (many rarely useful info, but not a mess like the debug level)许多很少有用的信息，但不像调试级别那样混乱
        # notice (moderately verbose, what you want in production probably)通知 适合生产 默认是这个
        # warning (only very important / critical messages are logged) 警告  只记录非常重要的信息
    日志文件：logfile ""   #日志文件输出名 为空
    默认数据库数量：databases 16
RDB配置：SNAPSHOTTING快照
    持久化规则 默认携带下面三种  可以自己定义   规定时间内,执行了多少次操作就会进行持久化到 rdb或aof文件中
        save 900 1     #900代表时间  如果900s内 有一个key进行了修改  就进行持久化操作
        save 300 10    #如果300s内 有10个key进行了修改  就进行持久化操作
        save 60 10000  #如果60s内 有1w个key进行了修改  就进行持久化操作
    异常是否继续工作：stop-writes-on-bgsave-error yes   #持久化错误之后是否继续工作  默认开启 避免大量数据丢失.启用监控时考虑设置no
    是否压缩RDB文件：rdbcompression yes                #是否压缩 rdb文件  默认(LZF算法)开启  压缩会消耗CPU资源 但是可以减小RDB文件的大小
    RDB文件校验：rdbchecksum yes             #保存 rdb文件的时候进行错误的校验  在写入文件和读取文件时都校验,关闭后文件损坏不容易发现
    持久化文件保存路径： dir ./                   # RDB文件和AOF文件所在目录
    RDB文件名：dbfilename dump.rdb
安全配置：SECURITY
    设置密码： requirepass 密码
    窗口指令：config get requirepass 获取  set 插入密码   auth "密码" 验证
    最大连接数：maxclients 10000   #连接redis的最大的客户端数,可以防止大量客户端连接消耗缓冲内存。
    最大内存:  maxmemory    #Redis最大内存设置(不设置64位无限制 32位3G)字节类型需要转换 转换看配置开头。一般设置物理内存的3/4.
AOF配置：APPEND ONLY MODE
    是否开启(默认no)： appendonly no    # 打开aof设置，同时将快照功能置于低优先级的位置
    持久化文件名:appendfilename "appendonly.aof"
    持久化规则：
        1.appendfsync always      #每次修改都会同步   速度比较慢 消耗性能
        2.appendfsync everysec    #每秒执行一次      sync同步 可能丢失这一秒数据
        3.appendfsync no          #不执行sync同步    操作系统自己同步数据  速度最快 一般不用
    缓冲区：no-appendfsync-on-rewrite:AOF保存期间客户端操作保存在缓冲区,但是如果断电会丢失,最多丢失30s。如果设置NO,保存期间客户端阻塞等待
REPLICATION 主从复制
     role:master       #角色  主机
     connected_slaves:0     #连接的从机   0个
     second_repl_offset:-1
--------------------------------------------------------------------------------------------
Redis持久化：redis基于内存操作 如果没有持久化 那么数据断电就消失了
1.RDB(redis database)方式：经过压缩的二进制文件
    1.手动触发：
        1.save：会阻塞Redis主进程,无法处理客户端的请求,直到RDB文件创建完毕,一般不会使用
        2.bgsave: fork一个子进程去调用rdbSave方法,RDB文件生成后向主进程发送完成信号,服务器可以处理客户端命令请求
    2.自动触发：
        1.配置文件中的save m秒内发生n次变化时，会触发bgsave
        2.在主从复制场景下，如果从节点执行全量复制操作，则主节点会执行bgsave命令，并将rdb文件发送给从节点
        3.shutdown命令时，自动执行rdb持久化。但是使用kill杀掉进程会丢失部分数据
    3.配置文件中save的实现原理？
        1.周期函数:，每100毫秒执行一次,检查配置是否满足,满足调用bgsave
        2.计数器:记录服务器进行了多少次修改,每次增删改操作进行+1
        3.时间戳:记录上一次save/bgsave的时间
    4.bgsave的执行流程？
        1.首先判断是否有save/bgsave/bgrewriteaof的进程,如果有不执行(同时执行,大量磁盘写会影响性能)
        2.fork一个子进程,子进程生成RDB文件然后对原RDB文件进行覆盖
        3.通知父进程完成bgsave操作,父进程更新时间戳和计数器
    5.保存路径
        1.dbfilename指定文件名,默认dump.rdb   通过dir配置RDB路径
    7.优点：
        1.是经过压缩的二进制文件,占用空间小,可以保存某个时间点的数据,我们可以根据问题还原回不同时间版本
        2.适合做容灾恢复,可以加密发送到其他数据中心
        3.fork子进程处理持久化,防止主进程阻塞,并且恢复的时候效率也比AOF高
    8.缺点：
        1.通过配置文件可以控制RDB频率,如果发送故障丢失数据多
        2.fork子进程时如果数据量大并且CPU繁忙可能导致阻塞时间超过1s
        3.采用copyOnWrite保证数据一致,主进程修改了一块内存就会复制一份提供子进程快照,极端情况下可能导致内存内存占用为原来2倍
2.AOF(append only file 追加文件)方式：
    1.触发机制
        1.手动触发：通过调用bgrewirteAOF
        2.自动触发：1.通过配置文件触发
    2.AOF配置方式
        1.always：每次修改都会将缓冲区内容写入到AOF文件,性能低
        2.everysec：每秒将缓冲区内容写入到AOF文件,但是实际可能存在超过2s的数据丢失
            1.save不在执行,距离上次超过1s,执行写入和保存
            2.save不在执行,距离上次没超过1s,执行写入但不保存
            3.save在执行,距离上次超过2s,执行写入但不保存
        3.no：所有操作放入缓冲区,当redis关闭或者缓冲区写满才进行写入AOF文件,性能高但是可能丢失大量数据
    3.为什么需要AOF重写？
        所有增删改执行都会进行保存,长时间堆积占用内存越来越大,通过重写可以将AOF文件大小
    4.AOF重写触发机制？
        通过配置文件配置AOF文件大小和增长率,当AOF文件超过指定大小并且增减率到达指定增长率调用bgrewriteaof命令进行重写
    5.AOF的重写方式？怎么保证数据安全？
        1.重写方式
            1.Redis4.0之前,将多条操作一个key的命令生成一个最终命令来降低AOF文件大小
            2.Redis4.0之后,直接将RDB文件覆盖到AOF中,再有写入操作继续追加,提高了重写速度也降低了AOF文件大小,因为RDB文件是压缩的
        2.保证数据安全
            1.重写的时候创建重写缓冲区,AOF创建完毕替换原有AOF文件,主进程将缓存指令追加到AOF文件中(主进程操作,所以会阻塞客户端)
        3.AOF重写缓冲区内容过多怎么办？
            内容过多会导致主进程阻塞时间长,所以redis在子进程重写时通过管道向主线程读取缓存事件
            每次读取1毫秒,最多执行1000次(1秒),如果20次没有读取到数据则结束这个过程,以这种方式减少缓冲区数据量来降低阻塞事件
    6.AOF数据恢复：    1.创建不带网络客户端2.取出写命令3.客户端执行写命令
        正常恢复：
            1.配置开启AOF 2.将AOF文件拷贝到Redis启动目录可以通过config get dir查看 3.重启redis
        异常恢复：
            1.配置开启AOF 2.AOF文件修复：会将错误的指令删除  redis-check-aof --fix appendonly.aof  3.重启Redis
    7.AOF优点：
        1.AOF通过每秒刷盘策略,就算出现故障也只是丢失2s数据,相比RDB丢失数据少
        2.AOF文件属于日志追加方式,部分损坏可以通过修复工具修复,如果错误执行了flush db可以通过AOF文件删除最后命令重新启动恢复数据
    8.AOF缺点：
        1.相对比RDB文件,AOF文件占用空间大,恢复速度比RDB慢
        2.曾经发送过的BUG：部分命令导致AOF文件无法恢复,例如:BRPOPLPISH 具体清空没有查到猜测应该是单线程恢复到这个进行阻塞,实际场景多线程问题
3.混合持久化
    混合持久化其实是对AOF重写的优化,将RDB文件放到AOF中,然后追加新插入命令
    1.优点：结合了RDB和AOF的优点,重写和恢复的性能增加
    2.缺点：兼容性差,reids4.0之前不兼容  2.AOF可读性变差
4.RDB、AOF、混合持久，我应该用哪一个？
    1.如果想要数据安全和性能兼容,可以使用混合持久化,数据恢复和AOF重写性能高,并且数据丢失可以承受在2秒
    2.如果可以承受几分钟的数据丢失,只是用RDB性能最高
    3.redis的使用为了提升性能,如果采用每次指令刷盘方式保证数据不丢失会造成性能严重下降,可以考虑使用MYSQL数据库
5.同时开启RDB和AOF，服务重启时如何加载？
    1.判断是否开启AOF,如果开启通过前缀(Redis)判断是否为混合,如果为混合先获取前面RDB文件进行恢复,然后创建伪客户端进行AOF格式数据恢复
-----------------------------------------------------------------------------------------------------------------
消息队列有什么用？
    常用场景：流量削锋,减缓数据库压力,日志记录,异步消息处理,应用解耦
1.使用过Redis做消息队列么,你是怎么用的？
    Redis自身提供了一些组件可以实现消息队列,但是仍然有一些缺点,所以项目中一般会使用成熟的技术进行使用(Kafka、Rocket MQ)
    1.list作消息队列 lpush生成rpop消费,while true循环进行读取消息
        缺点：1.消耗CPU性能   2.只能有一个消费者    3.生产者无法判断消费者是否消费    4.无法进行回滚
        解决方案：通过BLpushRpop解决1、3、4,但是消费者只能存在一个
    2.pub/sub订阅发布实现消息队列,实现一次生产多次消费
        缺点：1.消息没有持久化    2.后订阅的看不到前面发布的消息   3.网络断开、redis宕机消息就会丢弃
    3.使用Zset实现延时队列,当前时间+要延迟时间的时间戳当socre,消费者每次通过zset查询筛选出超过当前时间戳的任务进行执行
        缺点：1.需要注意失败回滚
2.Redis消息订阅:发布者和订阅者都是客户端,订阅的频道(channel)是服务器端.
    redis服务器保存所有频道(channel)和频道订阅者,当发布者在某频道发布消息会遍历所有订阅者进行消息发送
    发布者和订阅者指令？
        1.订阅者：subscribe channel channel1  一次可以订阅多个频道
        2.发布者：publish channel message     发布者指定频道发送消息
3.Redis发布订阅与MQ的比较？
    1.MQ支持多种协议进行数据传输
    2.MQ提供了消息持久化和消息回滚机制
    3.MQ主要功能就是订阅发布所以要比Redis功能覆盖面更广,如果项目场景简单,数据丢失不敏感,并且消息堆积概率小也可以使用Redis做消息队列
------------------------------------------------------------------------------------------
主从复制+读写分离：缓解一台服务器压力,提高吞吐量
    1.开启主从配置方式：使用 info replication查看主从配置
        1.从机配置文件配置 slaveof host ip | 高版本replicaof host ip 设置自己为从机,指向主机
        2.从机发送ping指令,检查连接状态是否正常,返回pong以外的结果说明连接异常,自动断开
        3.同步数据：
            1.全量复制：第一次同步数据或者无法继续进行增量复制则采用全量复制
            2.增量复制：用于网络中断后的复制,效率高,但是如果中断时间太久主服务器没有完整保存偏移量则会发生全量复制
        4.持续复制(命令传播)：从节点利用心跳向主节点发送消息
            1.检查主从服务器网络连接状态
            2.辅助从节点配置,降低延迟
            3.检测命令丢失
1.为什么会发生数据丢失?
    1.异步复制：主从节点复制是异步的,如果复制过程中主节点宕机会产生数据丢失
    2.脑裂导致数据丢失：主机脱离正常网络,和其他从机无法建立连接,哨兵会认为主机宕机,然后选举新的主机,而客户端还没有切换新主机还在往旧主机写数据,
      新主机重启后哨兵自动设置成从机,新写的数据会丢失
2.为什么会出现延迟与不一致的情况？
    1.命令传播时异步的,所以跟网络延迟有关
    2.配置文件可以设置立即发送还是合并多个tcp发送,如果合并多个TCP可能会增加延迟(一致性要求高的话不建议开启)
3.redis如何保证主从一致并且防止数据丢失? todo：解决1和2问题
    通过命令传播辅助从节点配置,当延迟时间大于指定时间的节点个数超过指定个数的话,主节点会拒绝写操作,降低延迟
4.主从复制的原理
    1.运行ID：从节点保存主节点随机生成ID,用于主节点判断是否是自己,如果不是进行全量复制
    2.偏移量：通过偏移量判断主从节点的同步状态(后续可用于哨兵选举优先级)
    3.缓冲区：默认1M,发生命令传播时不仅发送给从节点还会保存到缓冲区,通过从节点发来的偏移量判断未同步命令是否在缓冲区,如果存在进行增量复制,如果不存在说明断开时间太久,进行全量复制
    从节点首次连接只发送同步命令,主节点收到后进行全量复制。当从节点重连时发送运行ID和偏移量,主节点通过判断运行ID和偏移量进行全量复制和增量复制
5.主从发送RDB文件方式？
    1.通过socket传输(无磁盘化复制),适合磁盘速度慢网络环境好的场景使用    2.主节点先保存到磁盘然后发送给从节点(默认,适合采用硬盘的方式)
    通过配置可以指定等待时间(等待多个从节点上线一并发送)
6.主从复制存在问题？
    1.从节点重启,保存的线程ID和偏移量丢失会导致全量复制
       解决：正常关闭时将线程ID和偏移量保存到RDB文件中,重启读取
    2.redis发送故障切换,线程ID不一致发送全量复制
       解决：redis从节点切换成主节点之后生成自己线程ID的同时保留原主节点线程ID,判断相同之后尝试进行增量复制
7.过期key处理：
    1.从节点不会过期key,只会等待主节点过期key,然后发送del指令到从节点.所以可能出现主节点删除了而从节点还没有删除被读取到
8.为什么要弄主从复制或集群：
    一个redis会发生故障造成服务不可用,主从复制和集群可以分摊客户端请求,发送故障可以自动切换,实现高可用性
---------------------------------------------------------------------------------------------------
哨兵模式(sentinel)：只保证redis高可用,不能保证数据0丢失
1.为什么使用哨兵？
    主从模式下主机故障需要人工手动切换,可能造成一段时间不可用,哨兵可以通过选举自动将从节点切换成主节点
    作用：   监控+消息通知+故障转移
        1.通过发送命令检查主从机的运行状态,如果出现故障发消息给管理员
        2.检测到主机宕机,会进行自动选举主节点,通过发布订阅模式通知其他从节点连接到新主机
    缺点：
        一个哨兵监控可能存在问题,所以需要哨兵集群,哨兵直接还能互相监控
2.故障切换过程
    如果主机宕机,哨兵发现后会将状态切换为主观下线,当多个哨兵检测到主节点异常到达一定数量就称为客观下线,有一个哨兵发起投票进行选举,选举成功后通过发布订阅模式让从节点切换主机
3.选举算法考虑因素：
    1.优先级    2.复制的偏移量(看谁复制的数据多)    3.主从机断开连接的时长
--------------------------------------------------------------------------------------------
缓存穿透：
    用户查一个数据发现redis没有(缓存未命中),然后取数据库查,也没有,如果大量这个请求就会给数据库带来很大负载.就是缓存穿透
    解决方案：
      1.用户查完之后在缓存中放一个空值,同时设置过期时间,再次查询直接返回redis的空值。缺点：空对象太多会影响性能,可能出现数据不一致。
      2.布隆过滤器：是一种数据结构,查询结果以hash存储,会在控制层先校验,不符合就会丢弃.避免底层存储系统压力
      3.接口增加校验拦截无效请求(用户权限校验和参数校验)
      4.网关Nginx配置,单个IP每秒访问次数做限制
缓存击穿：
    当一个热点数据在不抗高并发时,如果key过期(访问数据库查询最新数据,并回写缓存),失效瞬间,高并发请求数据库导致数据库宕机
    解决方案：
      1.热点数据不过期：
      2.加互斥锁（分布式锁）：保证每个key只有一个线程查询数据库
缓存雪崩：
    在某一时间段,缓存集中过期,导致数据库崩溃  例如：Redis集群全部宕机。
    解决方案：
        1.异地多活,避免不可抗力因素导致全部宕机
        2.设置随机过期时间,让缓存失效的时间尽量均匀
        3.数据预热：在正式部署之前,将可能的被大量访问数据先访问一遍,提前加载进缓存.
        4.服务降级：比如双十一关闭一些不重要的服务,让他们走降级方法.来保证主服务的高可用性。
            1.参考日志自动降级 网络波动超时,可用率低。
            2.配置手动降级    出现错误 人工手动降级
预防雪崩：
    事前：1.异地多活,避免不可抗力因素导致全部宕机  2.设置随机过期时间   3.缓存预热    4.增加本地缓存(redis崩溃使用本地缓存支撑)
    事中：发生雪崩之后对redis访问限流,部分功能进行降级
    事后：1.使用RDB+AOF恢复数据  2.如果数据过旧进行数据预热
如何保证数据库和缓存的数据一致性
    引入缓存目的就是提高性能,如果想要强一致性可以去掉缓存,增加缓存采用读写串行执行,会降低性能
缓存如何更新：
    1.先删除缓存后更新数据库  问题：如果更新没完成其他线程执行查询会导致脏数据在缓存中
    2.先更新数据库后删除缓存  问题：线程查到脏数据写缓存之前另一个线程执行完更新删除了缓存也会导致脏数据在缓存中
        解决：1.延迟删除   2.采用分布式锁,写加锁    3.阿里cannal组件,监听binlog日志,有想要监听的操作发生时通知我们进行相应redis操作
    3.先更新数据库后更新缓存  问题：并发写入也会导致缓存为脏数据  2.多表组成的缓存会增加更新操作的等待时间
    4.写回(更新数据时只更新缓存,缓存异步【内存满了或进程退出】进行刷盘)  问题：1.实现复杂并且可能丢失数据
布隆过滤器：
    有多个哈希函数和一个位图组成,哈希计算后结果放入位图,如果结果都为1则存在
    缺点： 1.查询结果不确切    2.大数据量下长时间使用可能导致位图占满导致结果都为true
    如果降低误报：1.bitmap越da误报越低    2.哈希函数越多误报越低(效率也越低,位图占满时间越快误报率提高)
--------------------------------------------------------------------------------------------------------------
Redis内存：
1.使用info memory命令可以查看内存信息
    1.used_memory：使用内存大小
    2.used_memory_rss：实际占用内存大小
    内存碎片率 = 占用总内存 / 已使用内存
        内存碎片率>1:说明存在内存碎片,比值越大,内存碎片越严重
        内存碎片率<1:说明使用了虚拟内存(硬盘),硬盘操作慢,会导致redis性能下降
2.Redis内存消耗的划分
    1.数据对象
        采用key-value形式存储用户数据,每次根据数据类型分配相应空间
    2.缓冲内存
        1.客户端缓冲：客户端连接Redis产生的缓存,如果超过最大限制会断开连接,也可以控制连接数防止大量连接导致内存溢出
        2.AOF缓冲区：
    3.自身内存
    4.内存碎片
3.Redis内存回收策略
    1.删除过期数据(设置expire到期的key)
        1.定时任务删除
            创建一个定时任务,每10s运行一次,随机抽查20个key,如果过期率超过25%：循环执行定时任务直到低于25%为止,25毫秒过期时间
            如果任务过期则在每次事件之前执行一次快清理,每2s执行一次定时任务,判断过期率进行回收
        2.惰性删除
            不主动删除,当用户访问再进行删除     优点:节约CPU   缺点:如果一直不删除会占用内存,导致溢出
    2.内存使用达到最大时触发内存回收策略
        1.noeviction：默认策略,不删除任何key,直接返回错误
        2.allkeys-lru：全部key中使用LRU算法删除部分key
        4.allkeys-lfu：全部key中使用LFU算法删除部分key
        6.allkeys-random：全部key中随机删除部分key
        1.volatile-lru：设置超时时间的key中使用LRU算法删除部分key,如果没有可删除的,回退到默认策略
        3.volatile-lfu：设置超时时间的key中使用LFU算法删除部分key,如果没有可删除的,回退到默认策略
        5.volatile-random：设置超时时间的key中随机删除部分key,如果没有可删除的,回退到默认策略
        7.volatile-ttl：根据ttl命令删除剩余时间最短的key,如果没有可删除的,回退到默认策略
4.Redis的LRU算法怎么实现的？
    LRU:内部通过字段维护最后访问时间,创建一个默认缓冲池,每次取五个放入缓冲池,保留最大时间的key,然后淘汰最大的key依次循环直到释放足够内存
    LFU:最不经常使用的算法(内部需要维护使用次数,相对比复杂些)
5.如何避免redis内存占满导致不可写
    1.设置交换区,虽然性能低但是仍然可以写
    2.设置最大内存和回收策略,当内存占满自动进行回收释放空间
----------------------------------------------------------------------------------------------------------------
集群方案
    1.客户端分片
        采用hash算法将数据分布到节点上
        优点：1.每个实例相互独立
        缺点：1.不支持动态容缩  2.维护成本高
    2.Redis Cluster(服务器路由)
        一个集群有16384个槽,均匀分布到每个实例中。写入时通过hash计算的值%16384计算出具体槽位
        如何知道槽位属于哪个实例？
            所有redis实例有内部通讯,会通讯自己负责的槽位,返回给客户端进行缓存,计算出对应槽位去对应实例进行操作
        新增或删除实例时怎么处理？
            新增或删除时,redis内部负责槽位会变化,客户端按照原来缓存插入,如果被移动了就会告知客户端具体的实例。
            如果迁移未完成会携带ask告知客户端未完成,不需要缓存
        为什么槽位选用16384？
            具体不清楚,我觉得槽位太多会内部通讯的时候会造成数据包太大
        为什么采用槽位而不采用hash一致性算法？
            哈希槽实现简单,每次容缩只需要动对应槽位的数据,不需要动整个实例
        优点：支持动态扩容,免去代理层性能消耗    缺点：在线扩容出现错误需要人工干预
    2.代理方式
        客户端请求通过代理方式转发到正确节点
        1.Twtter 开源的 Twemproxy、codis：配置时创建1024槽,将槽分不到各节点,可以手动指定每个节点槽，也可以自动均匀分布槽
        优点：1.客户端不需要关心redis实例
        缺点：1.代理多了一次转发,消耗性能
分区缺点：
    1.批量插入或查询处理起来相对比复杂
    2.使用分区时生成RDB/AOF文件处理复杂
    3.节点动态扩容复杂
--------------------------------------------------------------------------------------------------------------------
1.分布式锁作用
    单台服务器可以通过lock,synchronized加锁,多台服务区则需要采用分布式锁来控制只有一个线程进行操作,保证线程安全
Redis实现分布式锁
    1.加锁：SET lock_key random_value NX PX 5000
        1.NX：键不存在进行插入,保证只有一个线程能获取锁
        2.PX：设置过期时间,防止线程报错无法解锁,导致死锁
        3.random_value 是客户端生成的唯一的字符串。
    2.解锁
        1.取出key对应的客户端字符串
        2.比对是否一致,一致就删除
        一般使用LUA脚本,保证原子性,防止中间插入操作影响锁性能
    存在问题：
        1.设置固定的过期时间,如果没有执行完或者网络延迟还是有问题
        2.不可重入锁
        3.如果加锁失败需要while(true)循环获取,耗费性能
        4.主从模式下,主节点拿锁到没同步给从节点就锁宕机了,发生故障恢复后新的主节点继续获取锁,这个时候锁获取多次,可能产生并发问题
            解决：1.通过红锁解决   2.通过zookeeper解决
    解决方案：引入redisson
        1.通过watchDog看门狗,设置过期时间30s,每10s查看客户端有没有宕机,如果没宕机过期时间刷新30s,保证客户端全部执行完
        2.通过hash类型,增加可重入锁,如果是一个客户端通过incrby+1,解锁decrby-1,当为0时删除key解锁
        3.采用订阅发布模式,加锁失败后订阅加锁的频道,当解锁后会在频道内发布消息,订阅者收到消息进行重试加锁
官方分布式锁方案：RedLock
    1.获取当前时间
    2.五个实例同时用相同KEY和VALUE获取锁,设置一个超时时间,小于失效时间,避免实例宕机长时间阻塞。
    3.客户端当前时间减去第一步时间计算出获取锁的时间,需要满足半数以上实例获取到锁,并且加锁时间要小于失效时间。才算真正拿到锁
    4.获取成功后锁超时时间为有效时间减去获取锁消耗的时间
    5.如果获取失败,将所有实例解锁(删除key)
    缺点: 1.成本高需要五个实例,性能低  2.依赖于系统时间,如果部分实例时间快一点可能导致超过有效时间提前释放锁
zookeeper实现分布式锁
    1.创建一个锁目录,获取锁需要到目录下创建有序节点
    2.判断本节点是否是第一个节点,如果是加锁执行业务,如果不是监听上一个节点的删除事件
    3.解锁只需要删除节点,后面节点监听到上一个节点删除执行继续加锁处理业务
ZK和redis选型
    1.zookeeper使用临时有序节点加锁解锁,可以避免宕机而产生死锁。
    2.zookeeper性能没有redis好,但是可以保证数据强一致性



集群分区    持久化数据扩容缩容
